version: '3'

vars:
  NAMESPACE: default
  GATEWAY_NAME: envoy-ai-gateway
  PRIMARY_BACKEND: llm-primary
  FALLBACK_BACKEND: llm-fallback
  MODEL: gpt-4
  PORT_FORWARD: 8080

tasks:
  default:
    desc: "Show available tasks"
    cmds:
      - task --list --sort=none

  prerequisites:
    desc: "Ensure 01-getting-started is deployed"
    dir: ../01-getting-started
    cmds:
      - task setup

  setup:
    desc: "Complete setup of the provider fallback demo"
    cmds:
      - task: prerequisites
      - task: deploy
      - task: wait-ready
      - echo "Provider fallback setup complete!"
      - echo "Run 'task test' to test the fallback behavior"
      - task: port-forward
    generates:
      - .task/setup.done
    status:
      - test -f .task/setup.done

  deploy:
    desc: "Deploy primary and fallback providers with gateway configuration"
    cmds:
      - kubectl apply -f primary-backend.yaml
      - kubectl apply -f fallback-backend.yaml
      - kubectl apply -f aigatewayroute-with-fallback.yaml
      - kubectl apply -f retry-policy.yaml
      - echo "Deployment initiated..."

  wait-ready:
    desc: "Wait for all components to be ready"
    cmds:
      - echo "Waiting for Primary Provider to be ready..."
      - kubectl wait --for=condition=ready pod -l app={{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} --timeout=300s
      - echo "Waiting for Fallback Provider to be ready..."
      - kubectl wait --for=condition=ready pod -l app={{.FALLBACK_BACKEND}} -n {{.NAMESPACE}} --timeout=300s
      - echo "All providers are ready!"
      - sleep 5

  port-forward:
    desc: "Start port forwarding (delegates to 01-getting-started)"
    dir: ../01-getting-started
    cmds:
      - task port-forward

  stop-port-forward:
    desc: "Stop port forwarding (delegates to 01-getting-started)"
    dir: ../01-getting-started
    cmds:
      - task stop-port-forward

  test:
    desc: "Run all test scenarios"
    deps: [test-normal, test-primary-failure, test-bulk-failures]
    cmds:
      - echo "All tests completed!"

  test-all-failure-modes:
    desc: "Test all failure modes with fallback"
    cmds:
      - task: test-rate-limit-fallback
      - task: test-auth-failure-fallback
      - task: test-context-length-fallback
      - task: test-server-error-fallback
      - task: test-model-not-found-fallback
      - task: test-mixed-failures-fallback
      - task: simulate-primary-recovery
      - echo "All failure mode tests completed!"

  test-rate-limit-fallback:
    desc: "Test rate limit errors trigger fallback"
    cmds:
      - task: simulate-rate-limit-failure
      - |
        echo "=== Testing rate limit fallback (HTTP 429 → fallback) ==="
        for i in {1..3}; do
          echo -e "\nRequest $i:"
          RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test rate limit fallback"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          HTTP_STATUS=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS:/d')
          
          echo "Final Status: $HTTP_STATUS"
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "✅ Fallback successful!"
            echo "$BODY" | jq -r '.choices[0].message.content // .' 2>/dev/null || echo "$BODY"
          else
            echo "❌ Request failed with status $HTTP_STATUS"
          fi
        done

  test-auth-failure-fallback:
    desc: "Test auth errors trigger fallback"
    cmds:
      - task: simulate-auth-failure
      - |
        echo "=== Testing auth failure fallback (HTTP 401 → fallback) ==="
        for i in {1..3}; do
          echo -e "\nRequest $i:"
          RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test auth failure fallback"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          HTTP_STATUS=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS:/d')
          
          echo "Final Status: $HTTP_STATUS"
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "✅ Fallback successful!"
            echo "$BODY" | jq -r '.choices[0].message.content // .' 2>/dev/null || echo "$BODY"
          else
            echo "❌ Request failed with status $HTTP_STATUS"
          fi
        done

  test-context-length-fallback:
    desc: "Test context length errors trigger fallback"
    cmds:
      - task: simulate-context-length-failure
      - |
        echo "=== Testing context length fallback (HTTP 400 → fallback) ==="
        for i in {1..3}; do
          echo -e "\nRequest $i:"
          RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test context length fallback"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          HTTP_STATUS=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS:/d')
          
          echo "Final Status: $HTTP_STATUS"
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "✅ Fallback successful!"
            echo "$BODY" | jq -r '.choices[0].message.content // .' 2>/dev/null || echo "$BODY"
          else
            echo "❌ Request failed with status $HTTP_STATUS"
          fi
        done

  test-server-error-fallback:
    desc: "Test server errors trigger fallback"
    cmds:
      - task: simulate-server-error-failure
      - |
        echo "=== Testing server error fallback (HTTP 503 → fallback) ==="
        for i in {1..3}; do
          echo -e "\nRequest $i:"
          RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test server error fallback"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          HTTP_STATUS=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS:/d')
          
          echo "Final Status: $HTTP_STATUS"
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "✅ Fallback successful!"
            echo "$BODY" | jq -r '.choices[0].message.content // .' 2>/dev/null || echo "$BODY"
          else
            echo "❌ Request failed with status $HTTP_STATUS"
          fi
        done

  test-model-not-found-fallback:
    desc: "Test model not found errors trigger fallback"
    cmds:
      - task: simulate-model-not-found-failure
      - |
        echo "=== Testing model not found fallback (HTTP 404 → fallback) ==="
        for i in {1..3}; do
          echo -e "\nRequest $i:"
          RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test model not found fallback"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          HTTP_STATUS=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS:/d')
          
          echo "Final Status: $HTTP_STATUS"
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "✅ Fallback successful!"
            echo "$BODY" | jq -r '.choices[0].message.content // .' 2>/dev/null || echo "$BODY"
          else
            echo "❌ Request failed with status $HTTP_STATUS"
          fi
        done

  test-mixed-failures-fallback:
    desc: "Test mixed failure types trigger fallback"
    cmds:
      - task: simulate-mixed-failures
      - |
        echo "=== Testing mixed failures fallback (multiple error types → fallback) ==="
        for i in {1..5}; do
          echo -e "\nRequest $i:"
          RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}" -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test mixed failures fallback"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          HTTP_STATUS=$(echo "$RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
          BODY=$(echo "$RESPONSE" | sed '/HTTP_STATUS:/d')
          
          echo "Final Status: $HTTP_STATUS"
          if [ "$HTTP_STATUS" = "200" ]; then
            echo "✅ Fallback successful!"
            echo "$BODY" | jq -r '.choices[0].message.content // .' 2>/dev/null || echo "$BODY"
          else
            echo "❌ Request failed with status $HTTP_STATUS"
          fi
        done

  test-normal:
    desc: "Test normal operation with healthy primary"
    cmds:
      - |
        echo "=== Testing normal operation (primary should handle requests) ==="
        for i in {1..3}; do
          echo -e "\nRequest $i:"
          curl -s -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Test normal operation"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions | jq -c .
        done

  test-primary-failure:
    desc: "Interactive timeout analysis demo - compares behavior with/without retry policy"
    cmds:
      - |
        # Export environment variables for the script
        export NAMESPACE={{.NAMESPACE}}
        export GATEWAY_NAME={{.GATEWAY_NAME}}
        export PRIMARY_BACKEND={{.PRIMARY_BACKEND}}
        export FALLBACK_BACKEND={{.FALLBACK_BACKEND}}
        export MODEL={{.MODEL}}
        export PORT_FORWARD={{.PORT_FORWARD}}
        
        # Run the interactive timeout analysis script
        ./test-timeout-analysis.sh

  test-bulk-failures:
    desc: "Send multiple requests to observe fallback behavior"
    cmds:
      - |
        echo "=== Testing bulk requests with intermittent failures ==="
        SUCCESS=0
        FAILED=0
        
        for i in {1..10}; do
          echo -n "Request $i: "
          RESPONSE=$(curl -s -w "%{http_code}" -o /tmp/response.json -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Bulk test request '$i'"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions)
          
          if [ "$RESPONSE" = "200" ]; then
            echo "✅ Success"
            ((SUCCESS++))
          else
            echo "❌ Failed (Status: $RESPONSE)"
            ((FAILED++))
          fi
        done
        
        echo -e "\n=== Summary ==="
        echo "Successful: $SUCCESS"
        echo "Failed: $FAILED"

  test-timeout:
    desc: "Test timeout and fallback behavior"
    cmds:
      - task: simulate-primary-slowness
      - |
        echo "=== Testing timeout scenario (primary slow, should use fallback) ==="
        START=$(date +%s)
        curl -s -H "Content-Type: application/json" \
          -d '{
            "model": "{{.MODEL}}",
            "messages": [{"role": "user", "content": "Test timeout behavior"}]
          }' \
          http://localhost:{{.PORT_FORWARD}}/v1/chat/completions | jq .
        END=$(date +%s)
        echo "Response time: $((END-START)) seconds"
      - task: simulate-primary-recovery

  test-circuit-breaker:
    desc: "Test circuit breaker activation"
    cmds:
      - |
        echo "=== Testing circuit breaker (send many failures to open circuit) ==="
        task simulate-primary-failure
        
        echo "Sending 10 rapid requests to trigger circuit breaker..."
        for i in {1..10}; do
          curl -s -H "Content-Type: application/json" \
            -d '{
              "model": "{{.MODEL}}",
              "messages": [{"role": "user", "content": "Circuit breaker test '$i'"}]
            }' \
            http://localhost:{{.PORT_FORWARD}}/v1/chat/completions > /dev/null
          echo -n "."
        done
        echo -e "\n"
        
        echo "Circuit breaker should now be open. Testing final request:"
        curl -s -H "Content-Type: application/json" \
          -d '{
            "model": "{{.MODEL}}",
            "messages": [{"role": "user", "content": "Final test after circuit open"}]
          }' \
          http://localhost:{{.PORT_FORWARD}}/v1/chat/completions | jq .
        
        task simulate-primary-recovery

  test-primary-health:
    desc: "Check primary provider health"
    cmds:
      - |
        echo "=== Checking primary provider health ==="
        kubectl exec -n {{.NAMESPACE}} deploy/{{.PRIMARY_BACKEND}} -- curl -s localhost:8000/v1/models | jq . || echo "Primary provider unhealthy"

  # Failure mode simulation tasks using LLM-D Inference Simulator capabilities
  simulate-rate-limit-failure:
    desc: "Simulate rate limit errors (HTTP 429)"
    cmds:
      - |
        echo "Configuring primary backend to return rate limit errors..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_FAILURE_INJECTION_RATE=80 \
          LLM_D_FAILURE_TYPE=rate_limit
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now returning 80% rate limit errors (HTTP 429)"

  simulate-auth-failure:
    desc: "Simulate authentication errors (HTTP 401)"
    cmds:
      - |
        echo "Configuring primary backend to return auth errors..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_FAILURE_INJECTION_RATE=70 \
          LLM_D_FAILURE_TYPE=invalid_api_key
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now returning 70% auth errors (HTTP 401)"

  simulate-context-length-failure:
    desc: "Simulate context length exceeded errors (HTTP 400)"
    cmds:
      - |
        echo "Configuring primary backend to return context length errors..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_FAILURE_INJECTION_RATE=60 \
          LLM_D_FAILURE_TYPE=context_length
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now returning 60% context length errors (HTTP 400)"

  simulate-server-error-failure:
    desc: "Simulate server errors (HTTP 503)"
    cmds:
      - |
        echo "Configuring primary backend to return server errors..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_FAILURE_INJECTION_RATE=90 \
          LLM_D_FAILURE_TYPE=server_error
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now returning 90% server errors (HTTP 503)"

  simulate-model-not-found-failure:
    desc: "Simulate model not found errors (HTTP 404)"
    cmds:
      - |
        echo "Configuring primary backend to return model not found errors..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_FAILURE_INJECTION_RATE=50 \
          LLM_D_FAILURE_TYPE=model_not_found
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now returning 50% model not found errors (HTTP 404)"

  simulate-mixed-failures:
    desc: "Simulate multiple failure types simultaneously"
    cmds:
      - |
        echo "Configuring primary backend with mixed failures..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_FAILURE_INJECTION_RATE=75 \

        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now returning 75% mixed failures (rate_limit, server_error, context_length)"

  simulate-primary-failure:
    desc: "Legacy: Make primary backend return generic errors"
    cmds:
      - task: simulate-server-error-failure

  simulate-primary-recovery:
    desc: "Restore primary backend to healthy state"
    cmds:
      - |
        echo "Restoring primary backend to healthy state..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_MODE=random \
          LLM_D_FAILURE_INJECTION_RATE=0 \
          LLM_D_FAILURE_TYPE=""
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend restored to healthy random mode"

  simulate-primary-slowness:
    desc: "Make primary backend slow (timeout scenario)"
    cmds:
      - |
        echo "Configuring primary backend to be slow..."
        kubectl set env deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} \
          LLM_D_RESPONSE_DELAY=15000
        kubectl rollout status deployment/{{.PRIMARY_BACKEND}} -n {{.NAMESPACE}}
        echo "Primary backend now slow (15s delay)"

  logs:
    desc: "Show logs from all components"
    cmds:
      - task: logs-primary
      - task: logs-fallback
      - task: logs-gateway

  logs-primary:
    desc: "Show logs from primary provider"
    cmds:
      - echo "=== Primary Provider Logs ==="
      - kubectl logs -l app={{.PRIMARY_BACKEND}} -n {{.NAMESPACE}} --tail=20 | jq -c .

  logs-fallback:
    desc: "Show logs from fallback provider"
    cmds:
      - echo "=== Fallback Provider Logs ==="
      - kubectl logs -l app={{.FALLBACK_BACKEND}} -n {{.NAMESPACE}} --tail=20 | jq -c .

  logs-gateway:
    desc: "Show gateway logs with retry/fallback events"
    cmds:
      - |
        echo "=== Gateway Logs (retry/fallback events) ==="
        ENVOY_POD=$(kubectl get pods -n envoy-gateway-system --selector=gateway.envoyproxy.io/owning-gateway-name={{.GATEWAY_NAME}} -o jsonpath='{.items[0].metadata.name}')
        kubectl logs -n envoy-gateway-system $ENVOY_POD --tail=20 | jq -c .

  show-retry-evidence:
    desc: "Show evidence of retry behavior and timeout differences"
    cmds:
      - |
        echo "=== RETRY POLICY STATUS ==="
        kubectl get backendtrafficpolicy retry-policy -n {{.NAMESPACE}} -o yaml 2>/dev/null || echo "❌ Retry policy not found"
        
        echo -e "\n=== GATEWAY RETRY METRICS ==="
        ENVOY_POD=$(kubectl get pods -n envoy-gateway-system --selector=gateway.envoyproxy.io/owning-gateway-name={{.GATEWAY_NAME}} -o jsonpath='{.items[0].metadata.name}')
        
        # Port forward to admin interface for detailed metrics
        kubectl port-forward -n envoy-gateway-system $ENVOY_POD 19001:19000 &
        PF_PID=$!
        sleep 3
        
        echo "📊 Upstream Request Metrics:"
        STATS=$(curl -s localhost:19001/stats)
        
        echo "--- Primary Backend Stats ---"
        echo "$STATS" | grep -E "cluster\.backend/default/{{.PRIMARY_BACKEND}}.*\.(upstream_rq_total|upstream_rq_5xx|upstream_rq_timeout|upstream_rq_retry|upstream_rq_retry_success|upstream_cx_connect_fail):" | head -10
        
        echo -e "\n--- Fallback Backend Stats ---"
        echo "$STATS" | grep -E "cluster\.backend/default/{{.FALLBACK_BACKEND}}.*\.(upstream_rq_total|upstream_rq_2xx|upstream_rq_timeout):" | head -10
        
        echo -e "\n--- Retry-Specific Metrics ---"
        echo "$STATS" | grep -E "retry\.(upstream_rq_retry|upstream_rq_retry_success|upstream_rq_retry_overflow):" || echo "No retry metrics found"
        
        echo -e "\n--- Circuit Breaker Status ---"
        echo "$STATS" | grep -E "circuit_breakers\..*\.(rq_open|cx_open):" | head -5
        
        echo -e "\n=== RECENT GATEWAY LOGS (showing retry attempts) ==="
        kubectl logs -n envoy-gateway-system $ENVOY_POD --tail=30 | grep -E "(retry|upstream_rq|timeout|circuit)" | tail -10 || echo "No retry-related logs in recent entries"
        
        kill $PF_PID 2>/dev/null || true
        
        echo -e "\n=== TIMEOUT COMPARISON GUIDE ==="
        echo "🕐 EXPECTED TIMING PATTERNS:"
        echo "   • No Retry Policy: ~1-5 seconds (fast failure)"
        echo "   • With Retry Policy: ~30-150 seconds (depends on failure type and retry success)"
        echo "   • Successful Fallback: Should complete within retry timeout"
        echo ""
        echo "🔍 EVIDENCE TO LOOK FOR:"
        echo "   1. upstream_rq_retry > 0 (retry attempts made)"
        echo "   2. Different response times in test phases"
        echo "   3. Primary backend errors followed by fallback success"
        echo "   4. Circuit breaker activation after multiple failures"

  metrics:
    desc: "Show fallback and retry metrics"
    cmds:
      - |
        ENVOY_POD=$(kubectl get pods -n envoy-gateway-system --selector=gateway.envoyproxy.io/owning-gateway-name={{.GATEWAY_NAME}} -o jsonpath='{.items[0].metadata.name}')
        echo "Collecting metrics from Envoy pod: $ENVOY_POD"
        
        # Port forward to admin interface
        kubectl port-forward -n envoy-gateway-system $ENVOY_POD 19000:19000 &
        PF_PID=$!
        sleep 3
        
        echo "=== Upstream Metrics ==="
        STATS=$(curl -s localhost:19000/stats)
        
        echo "--- Primary Provider ({{.PRIMARY_BACKEND}}) ---"
        echo "$STATS" | grep -E "cluster\.backend/default/{{.PRIMARY_BACKEND}}.*\.(upstream_rq_total|upstream_rq_5xx|upstream_rq_timeout|upstream_rq_retry|circuit_breakers)" | head -10
        
        echo -e "\n--- Fallback Provider ({{.FALLBACK_BACKEND}}) ---"
        echo "$STATS" | grep -E "cluster\.backend/default/{{.FALLBACK_BACKEND}}.*\.(upstream_rq_total|upstream_rq_5xx|upstream_rq_timeout|upstream_rq_retry)" | head -10
        
        echo -e "\n=== Retry Metrics ==="
        echo "$STATS" | grep -E "cluster\..*\.upstream_rq_retry(_success|_overflow):" | head -10
        
        echo -e "\n=== Circuit Breaker Status ==="
        echo "$STATS" | grep -E "circuit_breakers\..*\.(rq_open|cx_open|rq_pending_open):" | head -10
        
        kill $PF_PID 2>/dev/null || true

  status:
    desc: "Check status of all components"
    cmds:
      - echo "=== Deployments ==="
      - kubectl get deployments -n {{.NAMESPACE}} -l "app in ({{.PRIMARY_BACKEND}},{{.FALLBACK_BACKEND}})"
      - echo -e "\n=== Pods ==="
      - kubectl get pods -n {{.NAMESPACE}} -l "app in ({{.PRIMARY_BACKEND}},{{.FALLBACK_BACKEND}})"
      - echo -e "\n=== Services ==="
      - kubectl get svc -n {{.NAMESPACE}} | grep -E "({{.PRIMARY_BACKEND}}|{{.FALLBACK_BACKEND}})"
      - echo -e "\n=== AI Routes ==="
      - kubectl get aigatewayroute -n {{.NAMESPACE}}
      - echo -e "\n=== Backend Traffic Policy ==="
      - kubectl get backendtrafficpolicy -n {{.NAMESPACE}}

  show-config:
    desc: "Show applied configuration using kubectl"
    cmds:
      - echo "=== AI Gateway Route Configuration ==="
      - kubectl get aigatewayroute -n {{.NAMESPACE}} provider-fallback-route -o yaml
      - echo -e "\n=== Backend Traffic Policy Configuration ==="
      - kubectl get backendtrafficpolicy -n {{.NAMESPACE}} retry-policy -o yaml

  cleanup:
    desc: "Clean up all demo resources"
    cmds:
      - kubectl delete -f primary-backend.yaml --ignore-not-found=true
      - kubectl delete -f fallback-backend.yaml --ignore-not-found=true
      - kubectl delete -f aigatewayroute-with-fallback.yaml --ignore-not-found=true
      - kubectl delete -f retry-policy.yaml --ignore-not-found=true
      - rm -rf .task/
      - echo "Cleanup complete"